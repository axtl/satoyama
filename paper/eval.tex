\section{\label{sec:eval}Evaluation}

\begin{table*}
    \centering
    \begin{tabular}{l*{8}c}
        \toprule
        \multicolumn{1}{c}{\textbf{Server}} & \multicolumn{6}{c}{\textbf{GET}} & \multicolumn{2}{c}{\textbf{POST}} \\
        \cmidrule{2-9}
        & \multicolumn{2}{c}{100-all} & \multicolumn{2}{c}{100-single} & \multicolumn{2}{c}{1000-single} & \multicolumn{2}{c}{1000} \\
        & S & L & S & L & S & L & S & L \\ 
        \midrule
        \emph{Naka} & 4.83 & 4.96 & 838.08 & 413.71 & 720.86 & 673.97 & 654.51 & 763.50 \\
        \emph{Warusawa} & 2.85 & 2.96 & 99.45 & 113.24 & 142.75 & 137.62 & 142.88 & 123.82 \\
        \bottomrule
    \end{tabular}
    \caption{Average requests/second}
    \caption*{\textbf{GET} Legend}
        \begin{tabular}{*{2}l}
            \toprule
            \emph{100-all} & retrieve \texttt{/posts/} 100 times \\
            \emph{100-single} & retrieve \texttt{/posts/123/} 100 times \\
            \emph{1000-single} & retrieve \texttt{/posts/234/} 1000 times \\
            \bottomrule
        \end{tabular}
    \label{tab:eval}
\end{table*}

\subsubsection*{\label{sec:eval:rationale}Rationale}

Due to the non-relational nature of how the application stores its data~\ref{sec:impl:redis}, the time required to access a list of comments is the same as the time required to access a list of posts. For that reason, the evaluation only looks at creating and retrieving posts via the JSON API.

Only the JSON API is tested because there is no straightforward way of comparing the HTML and JavaScript clients. HTML generation happens (from templates) on the server-side, and would penalize the Python web server unfairly.

\subsubsection*{\label{sec:eval:mr}Method and Results}

Apache \textbf{ab}~\cite{ab} was used to drive the test harness against each of the two servers. HTTP \textbf{GET} and \textbf{POST} functionalities were tested, starting from an empty datastore. Table~\ref{tab:eval} shows the average number of requests per second, as reported by \textbf{ab}. Two testing scenarios are considered:

\begin{itemize}
    \item \textbf{Short} used a 52-byte text for each created post, in order to determine the maximum number of requests that the servers can sustain
    \item \textbf{Lorem} used a 3.4 kB text for each of the created posts, in order to better simulate real-life use of such an application
\end{itemize}

It is immediately noticeable that the Node.js server (Naka) is much faster than the Python server (Warusawa). In the \emph{100-all} test, Naka loads up the entire list of post titles and URLs from the backing store twice as fast than the Python server does. The biggest gap is in the \emph{100-single} test where Naka outperforms Warusawa \textbf{8.5x}.

For the \textbf{POST} results, it can be noticed that the \emph{Lorem} test for Naka took shorter than the \emph{Short} test; however, as the server is asynchronous, it returns to the client immediately upon request, and then sends the data to the backing store.
